{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook prepared by Henrique Lopes Cardoso (hlc@fe.up.pt), based on [Word2Vec Tutorial Notebook](https://github.com/kavgan/nlp-in-practice/tree/master/word2vec) by Kavita Ganesan and on [Gensim's documentation on the Word2Vec Model](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html).\n",
    "\n",
    "# WORD EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec in Gensim\n",
    "\n",
    "[Word2Vec](https://code.google.com/archive/p/word2vec/) is a model for training word embeddings that revolutionized the way words are represented. [Gensim](https://radimrehurek.com/gensim_3.8.3/models/word2vec.html) provides an implementation of the algorithm, with which we can train our own word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data\n",
    "\n",
    "Training embeddings requires a big corpus, the bigger the better.\n",
    "\n",
    "For illustration purposes, we'll make use of the (not very big) [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset, which includes full reviews of cars and hotels. More specifically, we'll use an 84MB compressed file with 255404 hotel reviews.\n",
    "\n",
    "This is how each review looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "data_file=\"reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open ('data/reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the whole dataset into a list, while providing some logging information.\n",
    "\n",
    "In the process of reading the data directly from the compressed file, we'll perform some pre-processing of the reviews using [gensim.utils.simple_preprocess](https://tedboy.github.io/nlps/generated/generated/gensim.utils.simple_preprocess.html). This does some basic pre-processing such as tokenization and lowercasing, and returns back a list of tokens (words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "            yield gensim.utils.simple_preprocess(line)\n",
    "    logging.info(\"Done reading data file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:07:10,643 : INFO : reading file data/reviews_data.txt.gz...this may take a while\n",
      "2023-06-01 16:07:10,645 : INFO : read 0 reviews\n",
      "2023-06-01 16:07:12,516 : INFO : read 10000 reviews\n",
      "2023-06-01 16:07:14,381 : INFO : read 20000 reviews\n",
      "2023-06-01 16:07:16,505 : INFO : read 30000 reviews\n",
      "2023-06-01 16:07:18,533 : INFO : read 40000 reviews\n",
      "2023-06-01 16:07:20,905 : INFO : read 50000 reviews\n",
      "2023-06-01 16:07:23,035 : INFO : read 60000 reviews\n",
      "2023-06-01 16:07:24,870 : INFO : read 70000 reviews\n",
      "2023-06-01 16:07:26,527 : INFO : read 80000 reviews\n",
      "2023-06-01 16:07:28,292 : INFO : read 90000 reviews\n",
      "2023-06-01 16:07:29,976 : INFO : read 100000 reviews\n",
      "2023-06-01 16:07:31,667 : INFO : read 110000 reviews\n",
      "2023-06-01 16:07:33,407 : INFO : read 120000 reviews\n",
      "2023-06-01 16:07:35,161 : INFO : read 130000 reviews\n",
      "2023-06-01 16:07:38,208 : INFO : read 140000 reviews\n",
      "2023-06-01 16:07:39,865 : INFO : read 150000 reviews\n",
      "2023-06-01 16:07:41,617 : INFO : read 160000 reviews\n",
      "2023-06-01 16:07:43,307 : INFO : read 170000 reviews\n",
      "2023-06-01 16:07:45,179 : INFO : read 180000 reviews\n",
      "2023-06-01 16:07:47,006 : INFO : read 190000 reviews\n",
      "2023-06-01 16:07:48,983 : INFO : read 200000 reviews\n",
      "2023-06-01 16:07:50,840 : INFO : read 210000 reviews\n",
      "2023-06-01 16:07:52,721 : INFO : read 220000 reviews\n",
      "2023-06-01 16:07:58,089 : INFO : read 230000 reviews\n",
      "2023-06-01 16:07:59,855 : INFO : read 240000 reviews\n",
      "2023-06-01 16:08:01,573 : INFO : read 250000 reviews\n",
      "2023-06-01 16:08:02,504 : INFO : Done reading data file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255404"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compressed file with the data\n",
    "data_file=\"data/reviews_data.txt.gz\"\n",
    "\n",
    "# read the tokenized reviews into a list\n",
    "documents = list(read_input(data_file))\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each review item becomes a list of words, so what we have is a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oct', 'nice', 'trendy', 'hotel', 'location', 'not', 'too', 'bad', 'stayed', 'in', 'this', 'hotel', 'for', 'one', 'night', 'as', 'this', 'is', 'fairly', 'new', 'place', 'some', 'of', 'the', 'taxi', 'drivers', 'did', 'not', 'know', 'where', 'it', 'was', 'and', 'or', 'did', 'not', 'want', 'to', 'drive', 'there', 'once', 'have', 'eventually', 'arrived', 'at', 'the', 'hotel', 'was', 'very', 'pleasantly', 'surprised', 'with', 'the', 'decor', 'of', 'the', 'lobby', 'ground', 'floor', 'area', 'it', 'was', 'very', 'stylish', 'and', 'modern', 'found', 'the', 'reception', 'staff', 'geeting', 'me', 'with', 'aloha', 'bit', 'out', 'of', 'place', 'but', 'guess', 'they', 'are', 'briefed', 'to', 'say', 'that', 'to', 'keep', 'up', 'the', 'coroporate', 'image', 'as', 'have', 'starwood', 'preferred', 'guest', 'member', 'was', 'given', 'small', 'gift', 'upon', 'check', 'in', 'it', 'was', 'only', 'couple', 'of', 'fridge', 'magnets', 'in', 'gift', 'box', 'but', 'nevertheless', 'nice', 'gesture', 'my', 'room', 'was', 'nice', 'and', 'roomy', 'there', 'are', 'tea', 'and', 'coffee', 'facilities', 'in', 'each', 'room', 'and', 'you', 'get', 'two', 'complimentary', 'bottles', 'of', 'water', 'plus', 'some', 'toiletries', 'by', 'bliss', 'the', 'location', 'is', 'not', 'great', 'it', 'is', 'at', 'the', 'last', 'metro', 'stop', 'and', 'you', 'then', 'need', 'to', 'take', 'taxi', 'but', 'if', 'you', 'are', 'not', 'planning', 'on', 'going', 'to', 'see', 'the', 'historic', 'sites', 'in', 'beijing', 'then', 'you', 'will', 'be', 'ok', 'chose', 'to', 'have', 'some', 'breakfast', 'in', 'the', 'hotel', 'which', 'was', 'really', 'tasty', 'and', 'there', 'was', 'good', 'selection', 'of', 'dishes', 'there', 'are', 'couple', 'of', 'computers', 'to', 'use', 'in', 'the', 'communal', 'area', 'as', 'well', 'as', 'pool', 'table', 'there', 'is', 'also', 'small', 'swimming', 'pool', 'and', 'gym', 'area', 'would', 'definitely', 'stay', 'in', 'this', 'hotel', 'again', 'but', 'only', 'if', 'did', 'not', 'plan', 'to', 'travel', 'to', 'central', 'beijing', 'as', 'it', 'can', 'take', 'long', 'time', 'the', 'location', 'is', 'ok', 'if', 'you', 'plan', 'to', 'do', 'lot', 'of', 'shopping', 'as', 'there', 'is', 'big', 'shopping', 'centre', 'just', 'few', 'minutes', 'away', 'from', 'the', 'hotel', 'and', 'there', 'are', 'plenty', 'of', 'eating', 'options', 'around', 'including', 'restaurants', 'that', 'serve', 'dog', 'meat']\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Word2Vec model\n",
    "\n",
    "To train a Word2Vec model, we instantiate Word2Vec and pass it the text we have loaded before. You can check the available options for [instantiation](https://radimrehurek.com/gensim_3.8.3/models/word2vec.html#gensim.models.word2vec.Word2Vec) and for [training](https://radimrehurek.com/gensim_3.8.3/models/word2vec.html#gensim.models.word2vec.Word2Vec.train).\n",
    "\n",
    "Training a Word2Vec model takes time, depending on your hardware. In this particular case, expect training to take something between 5 to 10 minutes on an Intel Core-i7 16GB desktop. I know, that's a very wide range, but of course it depends on which other processes are running in the same machine..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:08:20,186 : INFO : collecting all words and their counts\n",
      "2023-06-01 16:08:20,188 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-06-01 16:08:20,408 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2023-06-01 16:08:20,642 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2023-06-01 16:08:20,904 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2023-06-01 16:08:21,147 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2023-06-01 16:08:21,412 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2023-06-01 16:08:21,674 : INFO : PROGRESS: at sentence #60000, processed 11013726 words, keeping 76786 word types\n",
      "2023-06-01 16:08:21,892 : INFO : PROGRESS: at sentence #70000, processed 12637528 words, keeping 83199 word types\n",
      "2023-06-01 16:08:22,098 : INFO : PROGRESS: at sentence #80000, processed 14099754 words, keeping 88459 word types\n",
      "2023-06-01 16:08:22,311 : INFO : PROGRESS: at sentence #90000, processed 15662152 words, keeping 93357 word types\n",
      "2023-06-01 16:08:22,522 : INFO : PROGRESS: at sentence #100000, processed 17164490 words, keeping 97886 word types\n",
      "2023-06-01 16:08:22,737 : INFO : PROGRESS: at sentence #110000, processed 18652295 words, keeping 102132 word types\n",
      "2023-06-01 16:08:22,944 : INFO : PROGRESS: at sentence #120000, processed 20152532 words, keeping 105923 word types\n",
      "2023-06-01 16:08:23,161 : INFO : PROGRESS: at sentence #130000, processed 21684333 words, keeping 110104 word types\n",
      "2023-06-01 16:08:23,388 : INFO : PROGRESS: at sentence #140000, processed 23330209 words, keeping 114108 word types\n",
      "2023-06-01 16:08:23,605 : INFO : PROGRESS: at sentence #150000, processed 24838757 words, keeping 118174 word types\n",
      "2023-06-01 16:08:23,829 : INFO : PROGRESS: at sentence #160000, processed 26390913 words, keeping 118670 word types\n",
      "2023-06-01 16:08:24,028 : INFO : PROGRESS: at sentence #170000, processed 27913919 words, keeping 123356 word types\n",
      "2023-06-01 16:08:24,227 : INFO : PROGRESS: at sentence #180000, processed 29535615 words, keeping 126748 word types\n",
      "2023-06-01 16:08:24,426 : INFO : PROGRESS: at sentence #190000, processed 31096462 words, keeping 129847 word types\n",
      "2023-06-01 16:08:24,644 : INFO : PROGRESS: at sentence #200000, processed 32805274 words, keeping 133255 word types\n",
      "2023-06-01 16:08:24,845 : INFO : PROGRESS: at sentence #210000, processed 34434201 words, keeping 136364 word types\n",
      "2023-06-01 16:08:25,047 : INFO : PROGRESS: at sentence #220000, processed 36083485 words, keeping 139418 word types\n",
      "2023-06-01 16:08:25,240 : INFO : PROGRESS: at sentence #230000, processed 37571765 words, keeping 142399 word types\n",
      "2023-06-01 16:08:25,457 : INFO : PROGRESS: at sentence #240000, processed 39138193 words, keeping 145232 word types\n",
      "2023-06-01 16:08:25,658 : INFO : PROGRESS: at sentence #250000, processed 40695052 words, keeping 147966 word types\n",
      "2023-06-01 16:08:25,765 : INFO : collected 150059 word types from a corpus of 41519358 raw words and 255404 sentences\n",
      "2023-06-01 16:08:25,766 : INFO : Creating a fresh vocabulary\n",
      "2023-06-01 16:08:26,010 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 70537 unique words (47.01% of original 150059, drops 79522)', 'datetime': '2023-06-01T16:08:26.010869', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-06-01 16:08:26,011 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 41439836 word corpus (99.81% of original 41519358, drops 79522)', 'datetime': '2023-06-01T16:08:26.011872', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-06-01 16:08:26,357 : INFO : deleting the raw counts dictionary of 150059 items\n",
      "2023-06-01 16:08:26,363 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2023-06-01 16:08:26,364 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 30349251.36700416 word corpus (73.2%% of prior 41439836)', 'datetime': '2023-06-01T16:08:26.364950', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2023-06-01 16:08:26,959 : INFO : estimated required memory for 70537 words and 150 dimensions: 119912900 bytes\n",
      "2023-06-01 16:08:26,959 : INFO : resetting layer weights\n",
      "2023-06-01 16:08:27,075 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-06-01T16:08:27.075461', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2023-06-01 16:08:27,075 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 70537 vocabulary and 150 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-06-01T16:08:27.075461', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-06-01 16:08:28,148 : INFO : EPOCH 0 - PROGRESS: at 0.58% examples, 187741 words/s, in_qsize 18, out_qsize 1\n",
      "2023-06-01 16:08:29,178 : INFO : EPOCH 0 - PROGRESS: at 2.08% examples, 323170 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:30,191 : INFO : EPOCH 0 - PROGRESS: at 3.60% examples, 367229 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:31,199 : INFO : EPOCH 0 - PROGRESS: at 5.10% examples, 388254 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:32,199 : INFO : EPOCH 0 - PROGRESS: at 6.64% examples, 405182 words/s, in_qsize 20, out_qsize 0\n",
      "2023-06-01 16:08:33,207 : INFO : EPOCH 0 - PROGRESS: at 8.02% examples, 410180 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:34,234 : INFO : EPOCH 0 - PROGRESS: at 9.51% examples, 420708 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:35,257 : INFO : EPOCH 0 - PROGRESS: at 10.75% examples, 425196 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:36,298 : INFO : EPOCH 0 - PROGRESS: at 12.00% examples, 429426 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:37,308 : INFO : EPOCH 0 - PROGRESS: at 13.40% examples, 433539 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:38,329 : INFO : EPOCH 0 - PROGRESS: at 14.67% examples, 433791 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:39,336 : INFO : EPOCH 0 - PROGRESS: at 15.87% examples, 431779 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:40,342 : INFO : EPOCH 0 - PROGRESS: at 17.04% examples, 431028 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:41,343 : INFO : EPOCH 0 - PROGRESS: at 18.26% examples, 432593 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:42,367 : INFO : EPOCH 0 - PROGRESS: at 19.35% examples, 431179 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:43,369 : INFO : EPOCH 0 - PROGRESS: at 20.47% examples, 430666 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:44,406 : INFO : EPOCH 0 - PROGRESS: at 21.91% examples, 430880 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:45,407 : INFO : EPOCH 0 - PROGRESS: at 23.04% examples, 430875 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:46,417 : INFO : EPOCH 0 - PROGRESS: at 24.18% examples, 431796 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:47,431 : INFO : EPOCH 0 - PROGRESS: at 25.62% examples, 431531 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:48,447 : INFO : EPOCH 0 - PROGRESS: at 27.25% examples, 431340 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:49,473 : INFO : EPOCH 0 - PROGRESS: at 28.85% examples, 431232 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:50,476 : INFO : EPOCH 0 - PROGRESS: at 30.33% examples, 431210 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:51,500 : INFO : EPOCH 0 - PROGRESS: at 32.09% examples, 432036 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:52,501 : INFO : EPOCH 0 - PROGRESS: at 33.60% examples, 432323 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:08:53,502 : INFO : EPOCH 0 - PROGRESS: at 35.02% examples, 432123 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:54,523 : INFO : EPOCH 0 - PROGRESS: at 36.46% examples, 430485 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:55,525 : INFO : EPOCH 0 - PROGRESS: at 37.88% examples, 429738 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:56,527 : INFO : EPOCH 0 - PROGRESS: at 38.79% examples, 423652 words/s, in_qsize 18, out_qsize 1\n",
      "2023-06-01 16:08:57,539 : INFO : EPOCH 0 - PROGRESS: at 39.70% examples, 418325 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:58,541 : INFO : EPOCH 0 - PROGRESS: at 41.10% examples, 416925 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:08:59,599 : INFO : EPOCH 0 - PROGRESS: at 42.57% examples, 415973 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:00,626 : INFO : EPOCH 0 - PROGRESS: at 44.18% examples, 416168 words/s, in_qsize 20, out_qsize 0\n",
      "2023-06-01 16:09:01,668 : INFO : EPOCH 0 - PROGRESS: at 45.60% examples, 414661 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:02,680 : INFO : EPOCH 0 - PROGRESS: at 47.04% examples, 415001 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:03,695 : INFO : EPOCH 0 - PROGRESS: at 48.54% examples, 415326 words/s, in_qsize 20, out_qsize 0\n",
      "2023-06-01 16:09:04,729 : INFO : EPOCH 0 - PROGRESS: at 50.03% examples, 414998 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:05,747 : INFO : EPOCH 0 - PROGRESS: at 51.41% examples, 414666 words/s, in_qsize 20, out_qsize 0\n",
      "2023-06-01 16:09:06,761 : INFO : EPOCH 0 - PROGRESS: at 52.81% examples, 414932 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:07,776 : INFO : EPOCH 0 - PROGRESS: at 54.18% examples, 414844 words/s, in_qsize 20, out_qsize 0\n",
      "2023-06-01 16:09:08,781 : INFO : EPOCH 0 - PROGRESS: at 55.60% examples, 414239 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:09,783 : INFO : EPOCH 0 - PROGRESS: at 57.02% examples, 414190 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:10,788 : INFO : EPOCH 0 - PROGRESS: at 58.44% examples, 414228 words/s, in_qsize 20, out_qsize 0\n",
      "2023-06-01 16:09:11,804 : INFO : EPOCH 0 - PROGRESS: at 59.94% examples, 414534 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:12,819 : INFO : EPOCH 0 - PROGRESS: at 61.26% examples, 413577 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:13,821 : INFO : EPOCH 0 - PROGRESS: at 62.54% examples, 412739 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:14,830 : INFO : EPOCH 0 - PROGRESS: at 64.14% examples, 412653 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:15,845 : INFO : EPOCH 0 - PROGRESS: at 65.57% examples, 412768 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:16,848 : INFO : EPOCH 0 - PROGRESS: at 66.97% examples, 413079 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:17,872 : INFO : EPOCH 0 - PROGRESS: at 68.28% examples, 412270 words/s, in_qsize 20, out_qsize 0\n",
      "2023-06-01 16:09:18,940 : INFO : EPOCH 0 - PROGRESS: at 69.68% examples, 412095 words/s, in_qsize 18, out_qsize 1\n",
      "2023-06-01 16:09:19,953 : INFO : EPOCH 0 - PROGRESS: at 71.03% examples, 412388 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:20,961 : INFO : EPOCH 0 - PROGRESS: at 72.53% examples, 412715 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:21,966 : INFO : EPOCH 0 - PROGRESS: at 74.11% examples, 413013 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:22,968 : INFO : EPOCH 0 - PROGRESS: at 75.30% examples, 412310 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:23,982 : INFO : EPOCH 0 - PROGRESS: at 76.63% examples, 412544 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:25,010 : INFO : EPOCH 0 - PROGRESS: at 77.92% examples, 412305 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:26,024 : INFO : EPOCH 0 - PROGRESS: at 79.34% examples, 412546 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:27,029 : INFO : EPOCH 0 - PROGRESS: at 80.64% examples, 412469 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:28,072 : INFO : EPOCH 0 - PROGRESS: at 82.12% examples, 412610 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:29,100 : INFO : EPOCH 0 - PROGRESS: at 83.55% examples, 412755 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:30,118 : INFO : EPOCH 0 - PROGRESS: at 84.91% examples, 413031 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:31,126 : INFO : EPOCH 0 - PROGRESS: at 86.39% examples, 413266 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:32,131 : INFO : EPOCH 0 - PROGRESS: at 87.95% examples, 413425 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:33,136 : INFO : EPOCH 0 - PROGRESS: at 89.30% examples, 412940 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:34,159 : INFO : EPOCH 0 - PROGRESS: at 90.81% examples, 413004 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:35,166 : INFO : EPOCH 0 - PROGRESS: at 92.27% examples, 412932 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:36,196 : INFO : EPOCH 0 - PROGRESS: at 93.45% examples, 412196 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:37,197 : INFO : EPOCH 0 - PROGRESS: at 94.87% examples, 412089 words/s, in_qsize 20, out_qsize 0\n",
      "2023-06-01 16:09:38,224 : INFO : EPOCH 0 - PROGRESS: at 96.26% examples, 411929 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:39,239 : INFO : EPOCH 0 - PROGRESS: at 97.59% examples, 411398 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:40,240 : INFO : EPOCH 0 - PROGRESS: at 99.08% examples, 411596 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:40,826 : INFO : EPOCH 0: training on 41519358 raw words (30348383 effective words) took 73.7s, 411892 effective words/s\n",
      "2023-06-01 16:09:41,859 : INFO : EPOCH 1 - PROGRESS: at 1.14% examples, 364551 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:42,901 : INFO : EPOCH 1 - PROGRESS: at 2.57% examples, 393286 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:43,919 : INFO : EPOCH 1 - PROGRESS: at 4.01% examples, 404020 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:44,952 : INFO : EPOCH 1 - PROGRESS: at 5.40% examples, 406026 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:45,957 : INFO : EPOCH 1 - PROGRESS: at 6.62% examples, 399304 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:46,963 : INFO : EPOCH 1 - PROGRESS: at 7.95% examples, 402985 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:47,968 : INFO : EPOCH 1 - PROGRESS: at 9.28% examples, 406652 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:48,980 : INFO : EPOCH 1 - PROGRESS: at 10.41% examples, 409113 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:50,012 : INFO : EPOCH 1 - PROGRESS: at 11.58% examples, 410948 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:51,014 : INFO : EPOCH 1 - PROGRESS: at 12.64% examples, 410654 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:52,059 : INFO : EPOCH 1 - PROGRESS: at 13.99% examples, 412194 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:53,076 : INFO : EPOCH 1 - PROGRESS: at 15.25% examples, 413270 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:54,098 : INFO : EPOCH 1 - PROGRESS: at 16.51% examples, 414650 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:55,108 : INFO : EPOCH 1 - PROGRESS: at 17.66% examples, 415649 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:56,116 : INFO : EPOCH 1 - PROGRESS: at 18.90% examples, 417273 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:57,167 : INFO : EPOCH 1 - PROGRESS: at 20.00% examples, 417158 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:58,175 : INFO : EPOCH 1 - PROGRESS: at 21.41% examples, 418441 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:09:59,191 : INFO : EPOCH 1 - PROGRESS: at 22.54% examples, 418820 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:00,195 : INFO : EPOCH 1 - PROGRESS: at 23.64% examples, 419012 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:01,212 : INFO : EPOCH 1 - PROGRESS: at 24.79% examples, 418930 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:02,219 : INFO : EPOCH 1 - PROGRESS: at 26.42% examples, 419458 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:03,232 : INFO : EPOCH 1 - PROGRESS: at 28.04% examples, 419836 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:04,244 : INFO : EPOCH 1 - PROGRESS: at 29.55% examples, 420124 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:05,251 : INFO : EPOCH 1 - PROGRESS: at 31.09% examples, 419979 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:10:06,255 : INFO : EPOCH 1 - PROGRESS: at 32.64% examples, 420367 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:07,256 : INFO : EPOCH 1 - PROGRESS: at 34.07% examples, 420869 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:08,274 : INFO : EPOCH 1 - PROGRESS: at 35.59% examples, 421084 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:09,280 : INFO : EPOCH 1 - PROGRESS: at 37.10% examples, 421393 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:10,281 : INFO : EPOCH 1 - PROGRESS: at 38.65% examples, 421463 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:11,284 : INFO : EPOCH 1 - PROGRESS: at 40.09% examples, 421084 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:12,295 : INFO : EPOCH 1 - PROGRESS: at 41.76% examples, 421547 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:13,297 : INFO : EPOCH 1 - PROGRESS: at 43.26% examples, 421817 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:14,308 : INFO : EPOCH 1 - PROGRESS: at 44.84% examples, 421587 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:15,317 : INFO : EPOCH 1 - PROGRESS: at 46.27% examples, 420955 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:16,322 : INFO : EPOCH 1 - PROGRESS: at 47.45% examples, 419158 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:17,339 : INFO : EPOCH 1 - PROGRESS: at 48.73% examples, 417363 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:18,377 : INFO : EPOCH 1 - PROGRESS: at 50.13% examples, 416361 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:19,418 : INFO : EPOCH 1 - PROGRESS: at 51.60% examples, 416303 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:20,472 : INFO : EPOCH 1 - PROGRESS: at 52.94% examples, 416112 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:21,483 : INFO : EPOCH 1 - PROGRESS: at 54.38% examples, 416256 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:22,492 : INFO : EPOCH 1 - PROGRESS: at 55.97% examples, 416581 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:23,503 : INFO : EPOCH 1 - PROGRESS: at 57.39% examples, 416377 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:24,526 : INFO : EPOCH 1 - PROGRESS: at 58.78% examples, 416017 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:25,533 : INFO : EPOCH 1 - PROGRESS: at 60.28% examples, 416386 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:26,533 : INFO : EPOCH 1 - PROGRESS: at 61.71% examples, 416476 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:27,545 : INFO : EPOCH 1 - PROGRESS: at 63.08% examples, 415807 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:28,576 : INFO : EPOCH 1 - PROGRESS: at 64.82% examples, 415999 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:29,594 : INFO : EPOCH 1 - PROGRESS: at 66.19% examples, 416324 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:30,600 : INFO : EPOCH 1 - PROGRESS: at 67.41% examples, 415081 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:31,612 : INFO : EPOCH 1 - PROGRESS: at 68.51% examples, 413345 words/s, in_qsize 19, out_qsize 1\n",
      "2023-06-01 16:10:32,624 : INFO : EPOCH 1 - PROGRESS: at 69.66% examples, 412069 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:33,645 : INFO : EPOCH 1 - PROGRESS: at 70.82% examples, 411072 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:34,651 : INFO : EPOCH 1 - PROGRESS: at 71.83% examples, 409154 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:35,663 : INFO : EPOCH 1 - PROGRESS: at 73.06% examples, 407780 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:36,665 : INFO : EPOCH 1 - PROGRESS: at 74.26% examples, 406521 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:37,696 : INFO : EPOCH 1 - PROGRESS: at 75.32% examples, 404979 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:38,730 : INFO : EPOCH 1 - PROGRESS: at 76.32% examples, 403473 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:39,738 : INFO : EPOCH 1 - PROGRESS: at 77.41% examples, 402428 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:40,739 : INFO : EPOCH 1 - PROGRESS: at 78.38% examples, 400744 words/s, in_qsize 18, out_qsize 1\n",
      "2023-06-01 16:10:41,806 : INFO : EPOCH 1 - PROGRESS: at 79.39% examples, 398812 words/s, in_qsize 20, out_qsize 0\n",
      "2023-06-01 16:10:42,814 : INFO : EPOCH 1 - PROGRESS: at 80.58% examples, 398250 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:43,814 : INFO : EPOCH 1 - PROGRESS: at 81.80% examples, 397748 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:44,830 : INFO : EPOCH 1 - PROGRESS: at 83.07% examples, 397295 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:45,845 : INFO : EPOCH 1 - PROGRESS: at 84.29% examples, 396952 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:46,882 : INFO : EPOCH 1 - PROGRESS: at 85.41% examples, 396246 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:47,883 : INFO : EPOCH 1 - PROGRESS: at 86.59% examples, 395172 words/s, in_qsize 19, out_qsize 1\n",
      "2023-06-01 16:10:48,912 : INFO : EPOCH 1 - PROGRESS: at 87.80% examples, 394088 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:49,941 : INFO : EPOCH 1 - PROGRESS: at 89.06% examples, 393332 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:50,973 : INFO : EPOCH 1 - PROGRESS: at 90.32% examples, 392694 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:51,978 : INFO : EPOCH 1 - PROGRESS: at 91.60% examples, 392323 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:52,984 : INFO : EPOCH 1 - PROGRESS: at 92.85% examples, 391949 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:53,989 : INFO : EPOCH 1 - PROGRESS: at 94.13% examples, 391704 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:54,994 : INFO : EPOCH 1 - PROGRESS: at 95.62% examples, 392155 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:56,005 : INFO : EPOCH 1 - PROGRESS: at 97.07% examples, 392618 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:57,006 : INFO : EPOCH 1 - PROGRESS: at 98.51% examples, 392947 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:57,941 : INFO : EPOCH 1: training on 41519358 raw words (30348507 effective words) took 77.1s, 393655 effective words/s\n",
      "2023-06-01 16:10:58,966 : INFO : EPOCH 2 - PROGRESS: at 1.16% examples, 369714 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:10:59,985 : INFO : EPOCH 2 - PROGRESS: at 2.46% examples, 382398 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:01,025 : INFO : EPOCH 2 - PROGRESS: at 3.77% examples, 379745 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:02,031 : INFO : EPOCH 2 - PROGRESS: at 5.14% examples, 388799 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:03,048 : INFO : EPOCH 2 - PROGRESS: at 6.43% examples, 388733 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:04,118 : INFO : EPOCH 2 - PROGRESS: at 7.73% examples, 387752 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:05,188 : INFO : EPOCH 2 - PROGRESS: at 9.05% examples, 390138 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:06,227 : INFO : EPOCH 2 - PROGRESS: at 10.18% examples, 393171 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:07,248 : INFO : EPOCH 2 - PROGRESS: at 11.30% examples, 392584 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:08,258 : INFO : EPOCH 2 - PROGRESS: at 12.37% examples, 395203 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:09,259 : INFO : EPOCH 2 - PROGRESS: at 13.63% examples, 397252 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:10,273 : INFO : EPOCH 2 - PROGRESS: at 14.85% examples, 399587 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:11,285 : INFO : EPOCH 2 - PROGRESS: at 16.13% examples, 401791 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:12,323 : INFO : EPOCH 2 - PROGRESS: at 17.30% examples, 402853 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:13,352 : INFO : EPOCH 2 - PROGRESS: at 18.50% examples, 403948 words/s, in_qsize 18, out_qsize 1\n",
      "2023-06-01 16:11:14,362 : INFO : EPOCH 2 - PROGRESS: at 19.59% examples, 405245 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:15,365 : INFO : EPOCH 2 - PROGRESS: at 20.66% examples, 406565 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:16,396 : INFO : EPOCH 2 - PROGRESS: at 22.10% examples, 407098 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:17,427 : INFO : EPOCH 2 - PROGRESS: at 23.22% examples, 407761 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:18,430 : INFO : EPOCH 2 - PROGRESS: at 24.22% examples, 407042 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:11:19,452 : INFO : EPOCH 2 - PROGRESS: at 25.55% examples, 406119 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:20,462 : INFO : EPOCH 2 - PROGRESS: at 27.11% examples, 406562 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:21,479 : INFO : EPOCH 2 - PROGRESS: at 28.66% examples, 407081 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:22,481 : INFO : EPOCH 2 - PROGRESS: at 30.12% examples, 407481 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:23,507 : INFO : EPOCH 2 - PROGRESS: at 31.76% examples, 407800 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:24,529 : INFO : EPOCH 2 - PROGRESS: at 33.25% examples, 408353 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:25,552 : INFO : EPOCH 2 - PROGRESS: at 34.69% examples, 408967 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:26,563 : INFO : EPOCH 2 - PROGRESS: at 36.22% examples, 409635 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:27,579 : INFO : EPOCH 2 - PROGRESS: at 37.70% examples, 410177 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:28,584 : INFO : EPOCH 2 - PROGRESS: at 39.30% examples, 410825 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:29,602 : INFO : EPOCH 2 - PROGRESS: at 40.78% examples, 411275 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:30,632 : INFO : EPOCH 2 - PROGRESS: at 42.43% examples, 411753 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:31,644 : INFO : EPOCH 2 - PROGRESS: at 44.01% examples, 412269 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:32,659 : INFO : EPOCH 2 - PROGRESS: at 45.58% examples, 412233 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:33,669 : INFO : EPOCH 2 - PROGRESS: at 46.91% examples, 411855 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:34,680 : INFO : EPOCH 2 - PROGRESS: at 48.41% examples, 412297 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:35,682 : INFO : EPOCH 2 - PROGRESS: at 49.91% examples, 412608 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:36,692 : INFO : EPOCH 2 - PROGRESS: at 51.38% examples, 412974 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:37,708 : INFO : EPOCH 2 - PROGRESS: at 52.76% examples, 413090 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:38,709 : INFO : EPOCH 2 - PROGRESS: at 54.12% examples, 413193 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:39,724 : INFO : EPOCH 2 - PROGRESS: at 55.70% examples, 413552 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:40,749 : INFO : EPOCH 2 - PROGRESS: at 57.19% examples, 413626 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:41,749 : INFO : EPOCH 2 - PROGRESS: at 58.51% examples, 413233 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:42,759 : INFO : EPOCH 2 - PROGRESS: at 60.00% examples, 413472 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:43,827 : INFO : EPOCH 2 - PROGRESS: at 61.49% examples, 413329 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:44,852 : INFO : EPOCH 2 - PROGRESS: at 63.00% examples, 413546 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:45,866 : INFO : EPOCH 2 - PROGRESS: at 64.71% examples, 413820 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:46,886 : INFO : EPOCH 2 - PROGRESS: at 66.06% examples, 414007 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:47,911 : INFO : EPOCH 2 - PROGRESS: at 67.52% examples, 414086 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:48,929 : INFO : EPOCH 2 - PROGRESS: at 69.00% examples, 414315 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:49,939 : INFO : EPOCH 2 - PROGRESS: at 70.30% examples, 414408 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:50,954 : INFO : EPOCH 2 - PROGRESS: at 71.63% examples, 413975 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:51,987 : INFO : EPOCH 2 - PROGRESS: at 73.06% examples, 413668 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:53,016 : INFO : EPOCH 2 - PROGRESS: at 74.56% examples, 413779 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:54,050 : INFO : EPOCH 2 - PROGRESS: at 75.93% examples, 413863 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:55,074 : INFO : EPOCH 2 - PROGRESS: at 77.25% examples, 413995 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:56,075 : INFO : EPOCH 2 - PROGRESS: at 78.63% examples, 414170 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:57,082 : INFO : EPOCH 2 - PROGRESS: at 79.95% examples, 414066 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:58,086 : INFO : EPOCH 2 - PROGRESS: at 81.32% examples, 414205 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:11:59,100 : INFO : EPOCH 2 - PROGRESS: at 82.71% examples, 413944 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:00,127 : INFO : EPOCH 2 - PROGRESS: at 84.12% examples, 414047 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:01,140 : INFO : EPOCH 2 - PROGRESS: at 85.45% examples, 414216 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:02,165 : INFO : EPOCH 2 - PROGRESS: at 87.03% examples, 414466 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:03,166 : INFO : EPOCH 2 - PROGRESS: at 88.61% examples, 414738 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:04,168 : INFO : EPOCH 2 - PROGRESS: at 90.09% examples, 414917 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:05,196 : INFO : EPOCH 2 - PROGRESS: at 91.63% examples, 415141 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:06,235 : INFO : EPOCH 2 - PROGRESS: at 93.08% examples, 415252 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:07,259 : INFO : EPOCH 2 - PROGRESS: at 94.62% examples, 415475 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:08,267 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 415689 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:09,278 : INFO : EPOCH 2 - PROGRESS: at 97.59% examples, 415840 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:10,294 : INFO : EPOCH 2 - PROGRESS: at 99.10% examples, 415992 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:10,834 : INFO : EPOCH 2: training on 41519358 raw words (30350897 effective words) took 72.9s, 416415 effective words/s\n",
      "2023-06-01 16:12:11,850 : INFO : EPOCH 3 - PROGRESS: at 1.19% examples, 379766 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:12,889 : INFO : EPOCH 3 - PROGRESS: at 2.61% examples, 401489 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:13,900 : INFO : EPOCH 3 - PROGRESS: at 4.07% examples, 410333 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:14,911 : INFO : EPOCH 3 - PROGRESS: at 5.50% examples, 416456 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:15,927 : INFO : EPOCH 3 - PROGRESS: at 6.92% examples, 418028 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:16,930 : INFO : EPOCH 3 - PROGRESS: at 8.23% examples, 418821 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:17,943 : INFO : EPOCH 3 - PROGRESS: at 9.48% examples, 417779 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:18,959 : INFO : EPOCH 3 - PROGRESS: at 10.62% examples, 418637 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:19,995 : INFO : EPOCH 3 - PROGRESS: at 11.70% examples, 418384 words/s, in_qsize 20, out_qsize 0\n",
      "2023-06-01 16:12:21,046 : INFO : EPOCH 3 - PROGRESS: at 12.92% examples, 417457 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:22,077 : INFO : EPOCH 3 - PROGRESS: at 14.14% examples, 415683 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:23,089 : INFO : EPOCH 3 - PROGRESS: at 15.29% examples, 413693 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:24,102 : INFO : EPOCH 3 - PROGRESS: at 16.48% examples, 413097 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:25,118 : INFO : EPOCH 3 - PROGRESS: at 17.48% examples, 409973 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:26,145 : INFO : EPOCH 3 - PROGRESS: at 18.63% examples, 409724 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:27,153 : INFO : EPOCH 3 - PROGRESS: at 19.71% examples, 410674 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:28,196 : INFO : EPOCH 3 - PROGRESS: at 20.80% examples, 410813 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:29,217 : INFO : EPOCH 3 - PROGRESS: at 22.24% examples, 411292 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:30,252 : INFO : EPOCH 3 - PROGRESS: at 23.35% examples, 411664 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:31,264 : INFO : EPOCH 3 - PROGRESS: at 24.45% examples, 412365 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:12:32,290 : INFO : EPOCH 3 - PROGRESS: at 25.98% examples, 412832 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:33,334 : INFO : EPOCH 3 - PROGRESS: at 27.66% examples, 413241 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:34,351 : INFO : EPOCH 3 - PROGRESS: at 29.23% examples, 414055 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:35,369 : INFO : EPOCH 3 - PROGRESS: at 30.73% examples, 414230 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:36,393 : INFO : EPOCH 3 - PROGRESS: at 32.34% examples, 414563 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:37,392 : INFO : EPOCH 3 - PROGRESS: at 33.78% examples, 415238 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:38,428 : INFO : EPOCH 3 - PROGRESS: at 35.27% examples, 415370 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:39,467 : INFO : EPOCH 3 - PROGRESS: at 36.84% examples, 415669 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:40,474 : INFO : EPOCH 3 - PROGRESS: at 38.38% examples, 416088 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:41,495 : INFO : EPOCH 3 - PROGRESS: at 39.89% examples, 416353 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:42,497 : INFO : EPOCH 3 - PROGRESS: at 41.53% examples, 416863 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:43,506 : INFO : EPOCH 3 - PROGRESS: at 42.97% examples, 416752 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:44,510 : INFO : EPOCH 3 - PROGRESS: at 44.49% examples, 416121 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:45,535 : INFO : EPOCH 3 - PROGRESS: at 45.95% examples, 415459 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:46,553 : INFO : EPOCH 3 - PROGRESS: at 47.37% examples, 415700 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:47,586 : INFO : EPOCH 3 - PROGRESS: at 48.92% examples, 415807 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:48,597 : INFO : EPOCH 3 - PROGRESS: at 50.42% examples, 416085 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:49,611 : INFO : EPOCH 3 - PROGRESS: at 51.83% examples, 415948 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:50,612 : INFO : EPOCH 3 - PROGRESS: at 52.98% examples, 414896 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:51,617 : INFO : EPOCH 3 - PROGRESS: at 54.32% examples, 414418 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:52,634 : INFO : EPOCH 3 - PROGRESS: at 55.73% examples, 413494 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:53,644 : INFO : EPOCH 3 - PROGRESS: at 57.05% examples, 412685 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:54,644 : INFO : EPOCH 3 - PROGRESS: at 58.39% examples, 412318 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:55,653 : INFO : EPOCH 3 - PROGRESS: at 59.75% examples, 411591 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:56,660 : INFO : EPOCH 3 - PROGRESS: at 61.10% examples, 411106 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:57,667 : INFO : EPOCH 3 - PROGRESS: at 62.37% examples, 410306 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:58,671 : INFO : EPOCH 3 - PROGRESS: at 63.81% examples, 409682 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:12:59,677 : INFO : EPOCH 3 - PROGRESS: at 65.22% examples, 409205 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:00,705 : INFO : EPOCH 3 - PROGRESS: at 66.47% examples, 408656 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:01,720 : INFO : EPOCH 3 - PROGRESS: at 67.88% examples, 408551 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:02,729 : INFO : EPOCH 3 - PROGRESS: at 69.15% examples, 407967 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:03,752 : INFO : EPOCH 3 - PROGRESS: at 70.43% examples, 407827 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:04,765 : INFO : EPOCH 3 - PROGRESS: at 71.70% examples, 407277 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:05,768 : INFO : EPOCH 3 - PROGRESS: at 73.08% examples, 407045 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:06,784 : INFO : EPOCH 3 - PROGRESS: at 74.42% examples, 406478 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:07,801 : INFO : EPOCH 3 - PROGRESS: at 75.66% examples, 406059 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:08,803 : INFO : EPOCH 3 - PROGRESS: at 76.85% examples, 405616 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:09,825 : INFO : EPOCH 3 - PROGRESS: at 78.05% examples, 405283 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:10,843 : INFO : EPOCH 3 - PROGRESS: at 79.38% examples, 405011 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:11,864 : INFO : EPOCH 3 - PROGRESS: at 80.56% examples, 404263 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:12,881 : INFO : EPOCH 3 - PROGRESS: at 81.78% examples, 403544 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:13,883 : INFO : EPOCH 3 - PROGRESS: at 83.09% examples, 403303 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:14,909 : INFO : EPOCH 3 - PROGRESS: at 84.31% examples, 402784 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:15,915 : INFO : EPOCH 3 - PROGRESS: at 85.51% examples, 402510 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:16,936 : INFO : EPOCH 3 - PROGRESS: at 86.92% examples, 402176 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:17,959 : INFO : EPOCH 3 - PROGRESS: at 88.35% examples, 401959 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:18,964 : INFO : EPOCH 3 - PROGRESS: at 89.72% examples, 401769 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:19,975 : INFO : EPOCH 3 - PROGRESS: at 91.11% examples, 401532 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:20,993 : INFO : EPOCH 3 - PROGRESS: at 92.46% examples, 401266 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:21,996 : INFO : EPOCH 3 - PROGRESS: at 93.70% examples, 400864 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:22,998 : INFO : EPOCH 3 - PROGRESS: at 95.04% examples, 400715 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:24,012 : INFO : EPOCH 3 - PROGRESS: at 96.35% examples, 400397 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:25,028 : INFO : EPOCH 3 - PROGRESS: at 97.69% examples, 400220 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:26,054 : INFO : EPOCH 3 - PROGRESS: at 99.08% examples, 399959 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:26,675 : INFO : EPOCH 3: training on 41519358 raw words (30345594 effective words) took 75.8s, 400154 effective words/s\n",
      "2023-06-01 16:13:27,747 : INFO : EPOCH 4 - PROGRESS: at 1.14% examples, 346002 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:28,748 : INFO : EPOCH 4 - PROGRESS: at 2.37% examples, 362898 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:29,750 : INFO : EPOCH 4 - PROGRESS: at 3.70% examples, 373843 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:30,765 : INFO : EPOCH 4 - PROGRESS: at 5.00% examples, 376391 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:31,767 : INFO : EPOCH 4 - PROGRESS: at 6.21% examples, 377026 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:32,772 : INFO : EPOCH 4 - PROGRESS: at 7.50% examples, 379712 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:33,795 : INFO : EPOCH 4 - PROGRESS: at 8.71% examples, 378645 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:34,806 : INFO : EPOCH 4 - PROGRESS: at 9.77% examples, 380059 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:35,819 : INFO : EPOCH 4 - PROGRESS: at 10.81% examples, 379772 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:36,822 : INFO : EPOCH 4 - PROGRESS: at 11.76% examples, 379768 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:37,823 : INFO : EPOCH 4 - PROGRESS: at 12.81% examples, 379818 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:38,829 : INFO : EPOCH 4 - PROGRESS: at 13.99% examples, 380340 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:39,834 : INFO : EPOCH 4 - PROGRESS: at 15.08% examples, 380283 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:40,840 : INFO : EPOCH 4 - PROGRESS: at 16.23% examples, 380265 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:41,856 : INFO : EPOCH 4 - PROGRESS: at 17.27% examples, 380541 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:42,885 : INFO : EPOCH 4 - PROGRESS: at 18.31% examples, 380278 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:43,892 : INFO : EPOCH 4 - PROGRESS: at 19.31% examples, 380013 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:13:44,921 : INFO : EPOCH 4 - PROGRESS: at 20.28% examples, 379427 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:45,940 : INFO : EPOCH 4 - PROGRESS: at 21.59% examples, 379778 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:46,994 : INFO : EPOCH 4 - PROGRESS: at 22.62% examples, 379580 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:48,024 : INFO : EPOCH 4 - PROGRESS: at 23.68% examples, 380472 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:49,043 : INFO : EPOCH 4 - PROGRESS: at 24.67% examples, 380139 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:50,063 : INFO : EPOCH 4 - PROGRESS: at 26.03% examples, 379303 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:51,069 : INFO : EPOCH 4 - PROGRESS: at 27.45% examples, 379082 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:52,087 : INFO : EPOCH 4 - PROGRESS: at 28.94% examples, 379808 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:53,100 : INFO : EPOCH 4 - PROGRESS: at 30.18% examples, 379141 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:54,118 : INFO : EPOCH 4 - PROGRESS: at 31.62% examples, 378509 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:55,125 : INFO : EPOCH 4 - PROGRESS: at 32.98% examples, 378543 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:56,143 : INFO : EPOCH 4 - PROGRESS: at 34.18% examples, 378227 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:57,154 : INFO : EPOCH 4 - PROGRESS: at 35.48% examples, 378019 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:58,213 : INFO : EPOCH 4 - PROGRESS: at 36.91% examples, 378115 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:13:59,234 : INFO : EPOCH 4 - PROGRESS: at 38.32% examples, 378374 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:00,251 : INFO : EPOCH 4 - PROGRESS: at 39.64% examples, 378330 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:01,262 : INFO : EPOCH 4 - PROGRESS: at 41.03% examples, 378120 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:02,297 : INFO : EPOCH 4 - PROGRESS: at 42.53% examples, 378638 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:03,304 : INFO : EPOCH 4 - PROGRESS: at 43.94% examples, 378677 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:04,305 : INFO : EPOCH 4 - PROGRESS: at 45.35% examples, 378745 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:05,325 : INFO : EPOCH 4 - PROGRESS: at 46.73% examples, 379180 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:06,345 : INFO : EPOCH 4 - PROGRESS: at 48.02% examples, 379060 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:07,348 : INFO : EPOCH 4 - PROGRESS: at 49.41% examples, 379107 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:08,351 : INFO : EPOCH 4 - PROGRESS: at 50.73% examples, 379149 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:09,364 : INFO : EPOCH 4 - PROGRESS: at 52.08% examples, 379715 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:10,382 : INFO : EPOCH 4 - PROGRESS: at 53.21% examples, 379265 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:11,410 : INFO : EPOCH 4 - PROGRESS: at 54.49% examples, 378970 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:12,414 : INFO : EPOCH 4 - PROGRESS: at 55.91% examples, 379028 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:13,424 : INFO : EPOCH 4 - PROGRESS: at 57.18% examples, 378573 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:14,444 : INFO : EPOCH 4 - PROGRESS: at 58.32% examples, 377746 words/s, in_qsize 18, out_qsize 1\n",
      "2023-06-01 16:14:15,469 : INFO : EPOCH 4 - PROGRESS: at 59.75% examples, 378117 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:16,471 : INFO : EPOCH 4 - PROGRESS: at 61.08% examples, 378228 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:17,498 : INFO : EPOCH 4 - PROGRESS: at 62.39% examples, 378273 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:18,500 : INFO : EPOCH 4 - PROGRESS: at 63.84% examples, 378345 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:19,555 : INFO : EPOCH 4 - PROGRESS: at 65.37% examples, 378961 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:20,559 : INFO : EPOCH 4 - PROGRESS: at 66.74% examples, 379870 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:21,575 : INFO : EPOCH 4 - PROGRESS: at 68.26% examples, 380845 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:22,600 : INFO : EPOCH 4 - PROGRESS: at 69.68% examples, 381709 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:23,637 : INFO : EPOCH 4 - PROGRESS: at 71.05% examples, 382492 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:24,655 : INFO : EPOCH 4 - PROGRESS: at 72.56% examples, 383256 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:25,663 : INFO : EPOCH 4 - PROGRESS: at 74.15% examples, 384139 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:26,718 : INFO : EPOCH 4 - PROGRESS: at 75.50% examples, 384486 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:27,757 : INFO : EPOCH 4 - PROGRESS: at 76.85% examples, 385009 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:28,768 : INFO : EPOCH 4 - PROGRESS: at 78.19% examples, 385683 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:29,789 : INFO : EPOCH 4 - PROGRESS: at 79.63% examples, 386405 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:30,794 : INFO : EPOCH 4 - PROGRESS: at 81.01% examples, 387083 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:31,817 : INFO : EPOCH 4 - PROGRESS: at 82.50% examples, 387759 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:32,821 : INFO : EPOCH 4 - PROGRESS: at 83.93% examples, 388404 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:33,838 : INFO : EPOCH 4 - PROGRESS: at 85.22% examples, 388716 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:34,854 : INFO : EPOCH 4 - PROGRESS: at 86.73% examples, 389259 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:35,858 : INFO : EPOCH 4 - PROGRESS: at 88.30% examples, 389863 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:36,875 : INFO : EPOCH 4 - PROGRESS: at 89.82% examples, 390398 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:37,881 : INFO : EPOCH 4 - PROGRESS: at 91.37% examples, 390979 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:38,887 : INFO : EPOCH 4 - PROGRESS: at 92.77% examples, 391320 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:39,897 : INFO : EPOCH 4 - PROGRESS: at 94.23% examples, 391743 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:40,899 : INFO : EPOCH 4 - PROGRESS: at 95.69% examples, 392100 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:41,919 : INFO : EPOCH 4 - PROGRESS: at 97.15% examples, 392508 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:42,930 : INFO : EPOCH 4 - PROGRESS: at 98.64% examples, 392971 words/s, in_qsize 19, out_qsize 0\n",
      "2023-06-01 16:14:43,782 : INFO : EPOCH 4: training on 41519358 raw words (30350804 effective words) took 77.1s, 393647 effective words/s\n",
      "2023-06-01 16:14:43,805 : INFO : Word2Vec lifecycle event {'msg': 'training on 207596790 raw words (151744185 effective words) took 376.7s, 402809 effective words/s', 'datetime': '2023-06-01T16:14:43.799865', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2023-06-01 16:14:43,813 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=70537, vector_size=150, alpha=0.025>', 'datetime': '2023-06-01T16:14:43.813868', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:06:23.686567\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "model = gensim.models.Word2Vec(documents, vector_size=150, window=10, min_count=2, workers=10, sg=1)\n",
    "\n",
    "print(\"Training time:\", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploiting the Word2Vec model\n",
    "\n",
    "We can now inspect the word embeddings that we have trained. We can start by looking at the embeddings of a specific word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.56595814e-01,  8.00722480e-01, -1.50343150e-01,  3.13106596e-01,\n",
       "       -1.78973153e-02, -5.66125056e-03,  3.82428877e-02, -1.42356619e-01,\n",
       "        4.25188988e-02, -1.57804161e-01,  1.17257513e-01,  6.63125589e-02,\n",
       "        1.26103126e-02,  2.60465324e-01, -6.76033273e-02,  1.01392619e-01,\n",
       "       -1.00547954e-01,  2.61664748e-01, -5.45448512e-02, -3.01816851e-01,\n",
       "        3.32458653e-02,  1.47133857e-01,  1.36648372e-01, -2.31912985e-01,\n",
       "       -3.82015333e-02, -7.76402727e-02, -8.51919800e-02, -2.91402754e-03,\n",
       "        1.42763302e-01,  3.01458448e-01, -1.55419648e-01,  9.55241621e-02,\n",
       "       -1.12980437e-02, -5.54107837e-02, -1.55068651e-01, -4.73339632e-02,\n",
       "        1.02313414e-01,  3.23405638e-02, -1.18305452e-01, -5.28339595e-02,\n",
       "        3.72817904e-01, -7.04257339e-02, -8.35831277e-03, -1.83132619e-01,\n",
       "       -2.48425186e-01,  4.73089516e-03, -1.88391097e-02, -2.93081850e-01,\n",
       "        2.75182277e-01, -1.06561571e-01, -3.70598704e-01,  5.49557447e-01,\n",
       "       -1.16988003e-01,  1.17124438e-01,  1.71772674e-01, -2.95082659e-01,\n",
       "        1.30657166e-01,  3.08615655e-01, -2.72042036e-01, -5.30006528e-01,\n",
       "       -1.69553533e-01, -3.59055459e-01, -2.47918546e-01,  9.02796909e-03,\n",
       "       -1.00359477e-01, -1.28621086e-01, -1.93079412e-01,  1.70417964e-01,\n",
       "       -3.66027445e-01, -9.61528867e-02,  3.89182895e-01,  1.58276334e-01,\n",
       "       -1.76237687e-01, -3.40296090e-01, -4.77607511e-02, -1.57474428e-01,\n",
       "        1.07937984e-01,  1.17091313e-01, -1.35394499e-01, -1.56119525e-01,\n",
       "        2.65553981e-01, -4.01792496e-01, -1.21551543e-01,  5.12087345e-01,\n",
       "        5.69609180e-02,  6.01005256e-02,  3.42712015e-01, -2.36993313e-01,\n",
       "        3.13474566e-01,  9.62476134e-02,  1.62123993e-01,  1.47022724e-01,\n",
       "       -6.81473985e-02,  1.80111244e-01,  2.87832711e-02,  3.02877575e-01,\n",
       "        5.46009578e-02, -1.00242116e-01,  4.90516603e-01,  2.12615937e-01,\n",
       "        3.32834631e-01, -3.50646019e-01,  2.46832877e-01, -4.67332341e-02,\n",
       "       -1.00114815e-01, -1.14223816e-01, -1.67753443e-01,  2.42021188e-01,\n",
       "       -4.15902317e-01, -4.79119003e-01,  3.13209742e-01,  2.54186600e-01,\n",
       "        2.73237994e-04, -4.59938407e-01, -1.99525297e-01,  3.57028455e-01,\n",
       "       -6.70443289e-03,  1.56829134e-01, -8.52563009e-02, -5.81822157e-01,\n",
       "        1.96130157e-01,  7.16350526e-02,  8.49844635e-01,  1.26985759e-01,\n",
       "        9.24681351e-02,  2.19692159e-02, -1.49396107e-01,  3.11252400e-02,\n",
       "       -1.19449042e-01,  6.67487532e-02,  1.72858417e-01,  2.27459207e-01,\n",
       "       -1.18947618e-01, -9.92814302e-02, -3.67592961e-01,  4.52108122e-02,\n",
       "       -3.52353036e-01,  7.85446838e-02,  5.16564324e-02, -5.49919009e-02,\n",
       "        5.42215146e-02, -2.27247566e-01,  1.00994401e-01,  2.27669314e-01,\n",
       "        1.59302503e-02,  4.30944711e-01, -2.83150703e-01, -6.45221695e-02,\n",
       "       -2.17791498e-02, -9.99762714e-02], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings\n",
    "model.wv.get_vector(\"dirty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which are the words most similar to this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.8905879855155945),\n",
       " ('smelly', 0.8316246867179871),\n",
       " ('unclean', 0.8263578414916992),\n",
       " ('dusty', 0.8183785080909729),\n",
       " ('dingy', 0.8093951344490051),\n",
       " ('stained', 0.8060740828514099),\n",
       " ('grubby', 0.7994816899299622),\n",
       " ('moldy', 0.7968888282775879),\n",
       " ('disgusting', 0.7818449139595032),\n",
       " ('grimy', 0.7814695835113525)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity\n",
    "w1 = \"dirty\"\n",
    "model.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also limit to a smaller number of hits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.9033957123756409),\n",
       " ('professional', 0.8547850251197815),\n",
       " ('attentive', 0.8318154215812683),\n",
       " ('curtious', 0.8219287395477295),\n",
       " ('efficient', 0.8191940188407898),\n",
       " ('obliging', 0.8000189065933228)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'polite'\n",
    "w1 = [\"polite\"]\n",
    "model.wv.most_similar(positive=w1, topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.6906672120094299),\n",
       " ('england', 0.6704092025756836),\n",
       " ('spain', 0.6393370628356934),\n",
       " ('barcelona', 0.6390076875686646),\n",
       " ('paris', 0.6381335854530334),\n",
       " ('malaysia', 0.6348099112510681)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'france'\n",
    "w1 = [\"france\"]\n",
    "model.wv.most_similar(positive=w1, topn=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also provide to *most_similar* not only positive concepts, but also negative ones. This allows us to do some arithmetic on the vector representations for certain sets of words!\n",
    "\n",
    "The famous example **king - man + woman = queen** goes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7838140726089478)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arithmetic: vec(“king”) - vec(“man”) + vec(“woman”) =~ vec(“queen”)\n",
    "w1 = [\"king\",'woman']\n",
    "w2 = ['man']\n",
    "model.wv.most_similar(positive=w1, negative=w2, topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the similarity scores for specific word pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8316246"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"smelly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two identical words\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3736205"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two unrelated words\n",
    "model.wv.similarity(w1=\"dirty\", w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can check which word in a list of words is an intruder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"cat\", \"dog\", \"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"bed\", \"pillow\", \"duvet\", \"shower\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plane'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"car\", \"bicycle\", \"plane\", \"skate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bicycle'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"car\", \"bicycle\", \"bus\", \"trolley\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make your own experiments! Try to find out:\n",
    "- Which word is most similar to *lift*?\n",
    "- What are the 3 words most similar to *crab*?\n",
    "- How similar are the words *waitress* and *waiter*?\n",
    "- If you take *portugal*, remove *lisbon*, and add *dublin*, what do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading a Word2Vec model\n",
    "\n",
    "You can save a trained model so that you are able to load it again in the future, and optionally continue training it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:19:34,644 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'reviews_model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-06-01T16:19:34.644326', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-06-01 16:19:34,661 : INFO : storing np array 'vectors' to reviews_model.wv.vectors.npy\n",
      "2023-06-01 16:19:34,741 : INFO : storing np array 'syn1neg' to reviews_model.syn1neg.npy\n",
      "2023-06-01 16:19:34,810 : INFO : not storing attribute cum_table\n",
      "2023-06-01 16:19:34,870 : INFO : saved reviews_model\n"
     ]
    }
   ],
   "source": [
    "# save full model (including trainable vectors to resume training)\n",
    "model.save(\"reviews_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:20:01,839 : INFO : loading Word2Vec object from reviews_model\n",
      "2023-06-01 16:20:01,931 : INFO : loading wv recursively from reviews_model.wv.* with mmap=None\n",
      "2023-06-01 16:20:01,932 : INFO : loading vectors from reviews_model.wv.vectors.npy with mmap=None\n",
      "2023-06-01 16:20:01,966 : INFO : loading syn1neg from reviews_model.syn1neg.npy with mmap=None\n",
      "2023-06-01 16:20:02,004 : INFO : setting ignored attribute cum_table to None\n",
      "2023-06-01 16:20:02,567 : INFO : Word2Vec lifecycle event {'fname': 'reviews_model', 'datetime': '2023-06-01T16:20:02.567180', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "# load full model\n",
    "model = gensim.models.Word2Vec.load(\"reviews_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading the word embeddings\n",
    "\n",
    "If you're sure you won't be training the model any longer, you can save its *KeyedVectors* (the word embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:20:09,731 : INFO : KeyedVectors lifecycle event {'fname_or_handle': 'reviews_wv', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-06-01T16:20:09.731879', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "2023-06-01 16:20:09,732 : INFO : storing np array 'vectors' to reviews_wv.vectors.npy\n",
      "2023-06-01 16:20:09,788 : INFO : saved reviews_wv\n"
     ]
    }
   ],
   "source": [
    "# save model word vectors\n",
    "model.wv.save(\"reviews_wv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After saving the embeddings, you can load them and use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:20:29,967 : INFO : loading KeyedVectors object from reviews_wv\n",
      "2023-06-01 16:20:30,008 : INFO : loading vectors from reviews_wv.vectors.npy with mmap=None\n",
      "2023-06-01 16:20:30,035 : INFO : KeyedVectors lifecycle event {'fname': 'reviews_wv', 'datetime': '2023-06-01T16:20:30.035488', 'gensim': '4.2.0', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lifts', 0.8314789533615112)]\n"
     ]
    }
   ],
   "source": [
    "# load model word vectors\n",
    "wv = gensim.models.KeyedVectors.load(\"reviews_wv\")\n",
    "\n",
    "print(wv.most_similar(positive=\"lift\", topn=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Word embeddings can be visualized by reducing dimensionality of the words to 2 dimensions using [tSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).\n",
    "\n",
    "Given enough training data, we can observe certain patterns in the vector space, including:\n",
    "- Semantic relations: words like *cat*, *dog*, *cow*, etc. have a tendency to lie close by.\n",
    "- Syntactic relations: words like *run*, *running* or *cut*, *cutting* lie close together.\n",
    "- Arithmetic properties such as *King - Man = Queen - Woman*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def reduce_dimensions(model, num_dimensions=2, words=[]):\n",
    "\n",
    "    vectors = [] # positions in vector space\n",
    "    labels = [] # keep track of words to label our data again later\n",
    "    word_count = 0\n",
    "    \n",
    "    # if no word list is given, assume we want to use the whole data in the model\n",
    "    if(words == []):\n",
    "        words = model.wv.index_to_key\n",
    "\n",
    "    for word in words:\n",
    "        vectors.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    return vectors, labels\n",
    "\n",
    "\n",
    "# 2 dimension plotting\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels, words=[]):\n",
    "\n",
    "    random.seed(0)\n",
    "    \n",
    "    x_vals_new = np.array([])\n",
    "    y_vals_new = np.array([])\n",
    "    labels_new = np.array([])\n",
    "    if(words == []):\n",
    "        # if no word list is given, assume we want to plot the whole data\n",
    "        x_vals_new = x_vals\n",
    "        y_vals_new = y_vals\n",
    "        labels_new = labels\n",
    "    else:\n",
    "        for i in range(len(labels)):\n",
    "            if(labels[i] in words):\n",
    "                x_vals_new = np.append(x_vals_new,x_vals[i])\n",
    "                y_vals_new = np.append(y_vals_new,y_vals[i])\n",
    "                labels_new = np.append(labels_new,labels[i])\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals_new, y_vals_new)\n",
    "\n",
    "    # apply labels\n",
    "    for i in range(len(labels_new)):\n",
    "        plt.annotate(labels_new[i], (x_vals_new[i], y_vals_new[i]))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "words.extend([\"king\", \"man\", \"queen\", \"woman\"])\n",
    "\n",
    "vectors, labels = reduce_dimensions(model, 2, words)\n",
    "x_vals = [v[0] for v in vectors]\n",
    "y_vals = [v[1] for v in vectors]\n",
    "print(x_vals, y_vals, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_matplotlib(x_vals, y_vals, labels, [\"king\", \"man\", \"queen\", \"woman\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portuguese embeddings\n",
    "\n",
    "A number of embeddings for Portuguese are available at [NILC](http://nilc.icmc.usp.br/embeddings), as well as at the [NLX-group](https://github.com/nlx-group/LX-DSemVectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# takes a while to load...\n",
    "model_pt = KeyedVectors.load_word2vec_format('skip_s100.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model word vectors\n",
    "model_pt.save(\"pt_wv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model word vectors (much faster than the above)\n",
    "model_pt = gensim.models.KeyedVectors.load(\"pt_wv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pt.most_similar(positive=[\"cão\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pt.most_similar(positive=[\"rei\", \"mulher\"], negative=[\"homem\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make your own experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
