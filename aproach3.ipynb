{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  data  \\\n",
      "0  Contrairement aux idées reçues le traceur GPS est très précis, dumoins avec vivoactive 3 Music.....   \n",
      "1                                                                 Application très pratique et fiable.   \n",
      "2                                                                                     jadore ma montre   \n",
      "3                                Super application, je l'utilise synchronisé avec ma fenix3 et j'adore   \n",
      "4                                                                                              Super !   \n",
      "\n",
      "   score  rating  bug_report  feature_request  user_experience  \n",
      "0      5       1           0                0                1  \n",
      "1      5       1           0                0                0  \n",
      "2      5       1           0                0                0  \n",
      "3      5       1           0                0                1  \n",
      "4      5       1           0                0                0  \n"
     ]
    }
   ],
   "source": [
    "data_garmin_df = pd.read_csv('data/Garmin_Connect.csv')\n",
    "data_samsung_df = pd.read_csv('data/Samsung_Health.csv')\n",
    "data_huawei_df = pd.read_csv('data/Huawei_Health.csv')\n",
    "\n",
    "data = pd.concat([data_garmin_df, data_samsung_df, data_huawei_df], ignore_index=True)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employing non-alphabetic filtering, lowercasing, stop word removal, and stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    contrair id re ue traceur gp tr pr ci dumoin vivoact music tr motiv suit conseil garmin\n",
      "1                                                                    applic tr pratiqu fiabl\n",
      "2                                                                                jador montr\n",
      "3                                                   super applic utilis synchroni fenix ador\n",
      "4                                                                                      super\n",
      "Name: text_clean, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "corpus = []\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "def clean_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sw = set(stopwords.words('french'))\n",
    "    # get review and remove non alpha chars\n",
    "    review = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # to lower-case\n",
    "    review = review.lower()\n",
    "    # split into tokens, apply stemming and remove stop words\n",
    "    #review = ' '.join([lemmatizer.lemmatize(w) for w in review.split()])\n",
    "    return ' '.join([ps.stem(w) for w in review.split() if w not in sw])\n",
    "\n",
    "\n",
    "data['text_clean'] = data['data'].apply(lambda x: clean_text(x))\n",
    "print(data['text_clean'].head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into test and train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3682    aim bien cett applic comm a peut dire combien a fait mar v lo sport plein autr aussi pouvez choisir\n",
      "3067                                                                                 bonn applic fi tr bien\n",
      "2487                                                          dommag puiss mesur stress rythm cardiaqu note\n",
      "4622                                                                                                  super\n",
      "5160                                                  fonctionn bien depui mise jour r veill matin pad fait\n",
      "                                                       ...                                                 \n",
      "420                                                                                                    cool\n",
      "5848                                                                              temp sommeil rest parfait\n",
      "5191                                          a nouveau acc diff rent fond cran plu connexion phone one plu\n",
      "3166                                                                                          tr bonn appli\n",
      "3879                                                                                                    top\n",
      "Name: text_clean, Length: 4800, dtype: object       rating  bug_report  feature_request  user_experience\n",
      "3682       1           0                0                1\n",
      "3067       1           0                0                1\n",
      "2487       0           0                1                0\n",
      "4622       1           0                0                0\n",
      "5160       0           1                0                0\n",
      "...      ...         ...              ...              ...\n",
      "420        1           0                0                0\n",
      "5848       1           0                1                0\n",
      "5191       0           1                0                0\n",
      "3166       1           0                0                0\n",
      "3879       1           0                0                0\n",
      "\n",
      "[4800 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "y = data[['rating','bug_report','feature_request','user_experience']]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text_clean'],y , test_size=0.2,stratify=y, random_state=42)\n",
    "print(X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Marta\n",
      "[nltk_data]     Mariz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "nltk.download('stopwords')\n",
    "\n",
    "final_stopwords_list = stopwords.words('english') + stopwords.words('french')\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8,\n",
    "                                   max_features=200000,\n",
    "                                   min_df=0.2,\n",
    "                                   stop_words=final_stopwords_list,\n",
    "                                   use_idf=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.2816000845487212, 'recall': 0.4629042485732403, 'f1': 0.35017627094141496}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marta Mariz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    \"\"\"Calculate precision, recall, and f1 score\"\"\"\n",
    "\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    performance = {'precision': metrics[0], 'recall': metrics[1], 'f1': metrics[2]}\n",
    "    return performance\n",
    "\n",
    "\n",
    "print(score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcfe8c9e21b55aa01906cc0de6370d442d81bec12f7f116beb357c60c30ba9f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
