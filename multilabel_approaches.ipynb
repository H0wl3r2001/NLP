{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data  score  rating  \\\n",
      "0  Contrairement aux idées reçues le traceur GPS ...      5       1   \n",
      "1               Application très pratique et fiable.      5       1   \n",
      "2                                   jadore ma montre      5       1   \n",
      "3  Super application, je l'utilise synchronisé av...      5       1   \n",
      "4                                            Super !      5       1   \n",
      "5  Application très pratique et très simple d'uti...      3       1   \n",
      "6  Suivis du sommeil cardio nombre de pas avec la...      5       1   \n",
      "7                                  Sympa et précis !      5       1   \n",
      "8                                     Très satisfait      5       1   \n",
      "9  bonjour, le calendrier ne se synchronise plus....      2       0   \n",
      "\n",
      "   bug_report  feature_request  user_experience  \n",
      "0           0                0                1  \n",
      "1           0                0                0  \n",
      "2           0                0                0  \n",
      "3           0                0                1  \n",
      "4           0                0                0  \n",
      "5           1                0                0  \n",
      "6           0                0                1  \n",
      "7           0                0                0  \n",
      "8           0                0                0  \n",
      "9           1                0                0  \n",
      "\n",
      " Number of rows: 6000\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data from the file\n",
    "data_garmin_df = pd.read_csv('data/Garmin_Connect.csv')\n",
    "data_samsung_df = pd.read_csv('data/Samsung_Health.csv')\n",
    "data_huawei_df = pd.read_csv('data/Huawei_Health.csv')\n",
    "\n",
    "data = pd.concat([data_garmin_df, data_samsung_df, data_huawei_df], ignore_index=True)\n",
    "#data.to_csv('data/concatenated_data.csv', sep='\\t', encoding='utf-8')\n",
    "\n",
    "print(data.head(10))\n",
    "print(\"\\n Number of rows: \" + str(len(data)))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and removal of stopwords\n",
    "\n",
    "*Tokenization* is the process of splitting an input text into tokens (words or other relevant elements, such as punctuation, empty strings). We will use the result as a basis to predict a label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\radio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data  score  rating  \\\n",
      "0  Contrairement aux idées reçues le traceur GPS ...      5       1   \n",
      "1               Application très pratique et fiable.      5       1   \n",
      "2                                   jadore ma montre      5       1   \n",
      "3  Super application, je l'utilise synchronisé av...      5       1   \n",
      "4                                            Super !      5       1   \n",
      "\n",
      "   bug_report  feature_request  user_experience  \\\n",
      "0           0                0                1   \n",
      "1           0                0                0   \n",
      "2           0                0                0   \n",
      "3           0                0                1   \n",
      "4           0                0                0   \n",
      "\n",
      "                                               token  \n",
      "0  contrair aux id e re ue le traceur gp est tr s...  \n",
      "1                      appliqu tr s pratiqu et fiabl  \n",
      "2                                     jador ma montr  \n",
      "3  sup appliqu je l utilis synchron avec ma fenix...  \n",
      "4                                                sup  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize #principal tokenization class from nltk API\n",
    "from nltk.stem import SnowballStemmer   #Stemming method\n",
    "import re                               #regex library\n",
    "nltk.download('punkt')\n",
    "\n",
    "## IMPLEMENT LEMMATIZATION\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    review = re.sub('\\*', '', row[\"data\"]) # get data, substitute asterisks for empty string, put into review\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review) # from review, remove all non-alphabetic characters\n",
    "    review = re.sub('[^\\w\\s]', '', review) # remove punctuation from review\n",
    "    review = ' '.join([SnowballStemmer('french').stem(w) for w in word_tokenize(review.lower(), language='french')]) # apply stemming\n",
    "    corpus.append(review)\n",
    "\n",
    "#print(corpus)\n",
    "\n",
    "data = data.assign(token=corpus)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separation between train and test datasets\n",
    "\n",
    "Separate in adequate proportions to avoid the overfitting of the modules the data between features and targets. In this case there will be 2 different separations, one for the original multilabel problem and another for the mold into just a multiclass problem. To ensure a more even tag distribution, we must use the *stratify* hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800,)\n",
      "(1200,)\n",
      "(4800, 4)\n",
      "(1200, 4)\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = data['data']  # try to include / exclude score and check if it yields better results\n",
    "y = data[['rating', 'bug_report', 'feature_request', 'user_experience']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approaches to multilabel classification we will consider:\n",
    "\n",
    "#### Problem transformation\n",
    "1. Binary Relevance (consider each label as a separate single class classification  problem)\n",
    "2. Classifier Chains\n",
    "3. Label powerset\n",
    "\n",
    "#### Adapted Algorithms\n",
    "\n",
    "#### Ensemble methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best parameters for TF-IDF Transformer and CountVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two preprocessing steps will be present in all of our pipelines, so lets check what hyperparameters are best for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "nltk.download('stopwords')\n",
    "\n",
    "final_stopwords_list = stopwords.words('french') + stopwords.words('english')\n",
    "# Define the hyperparameters to tune for the TfidfTransformer, which will be the same for every method approach as this preprocessor is always used\n",
    "tfidf_params = {\n",
    "    'use_idf': [True, False],\n",
    "    'smooth_idf': [True, False],\n",
    "    'sublinear_tf': [True, False],\n",
    "    'norm': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "#Define the hyperparameters to tune for the CountVectorizer, which will be the same for every method approach as this preprocessor is always used\n",
    "count_vectorizer_params = {\n",
    "    'max_df': [0.5, 0.75, 1.0],\n",
    "    'min_df': [0.2, 0.25, 0.3],\n",
    "    'max_features': [None, 10000, 20000],\n",
    "    'ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'stop_words': [None, final_stopwords_list],\n",
    "}\n",
    "\n",
    "grid_params = {\n",
    "        'vect__max_df': count_vectorizer_params['max_df'],\n",
    "        'vect__ngram_range': count_vectorizer_params['ngram_range'],\n",
    "        'vect__min_df': count_vectorizer_params['min_df'],\n",
    "        'vect__stop_words': count_vectorizer_params['stop_words'],\n",
    "        'tfidf__use_idf': tfidf_params['use_idf'],\n",
    "        'tfidf__smooth_idf': tfidf_params['smooth_idf'],\n",
    "        'tfidf__sublinear_tf': tfidf_params['sublinear_tf'],\n",
    "        'tfidf__norm': tfidf_params['norm'],\n",
    "        \n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "grid_search = GridSearchCV(pipeline, grid_params, cv=2, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters:\" , grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameters for count_vectorizer and tf_idf_transformer\n",
    "So we don't have to run the gridSearch multiple times \n",
    "\n",
    "Best parameters: \n",
    "- 'tfidf__norm': 'l1'\n",
    "- 'tfidf__smooth_idf': True\n",
    "- 'tfidf__sublinear_tf': True\n",
    "- 'tfidf__use_idf': True\n",
    "- 'vect__max_df': 0.7\n",
    "- 'vect__min_df': 0.3\n",
    "- 'vect__ngram_range': (1, 2)\n",
    "- 'vect__stop_words': final_stopwords_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new count vectorizer with the best parameters\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=0.2,\n",
    "    stop_words=final_stopwords_list,\n",
    ")\n",
    "\n",
    "tf_idf_transformer = TfidfTransformer(\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True,\n",
    "    norm='l1',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preprocessing, tokenizing and filtering of stopwords are all included in CountVectorizer, which builds a dictionary of features and transforms documents to feature vectors; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def make_pipeline(clf_param_grid, clf):\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', count_vectorizer),\n",
    "        ('tfidf', tf_idf_transformer),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "\n",
    "    # Define the GridSearchCV object to tune the hyperparameters\n",
    "    grid_params = [\n",
    "        {\n",
    "        **clf_param\n",
    "        }\n",
    "        for clf_param in clf_param_grid\n",
    "    ]\n",
    "\n",
    "    # Define the GridSearchCV object\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=grid_params, cv=5, n_jobs=-1)\n",
    "\n",
    "\n",
    "    # Fit the GridSearchCV object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters and best model\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(\"Best parameters: \", best_params)\n",
    "    print(\"Best model: \", best_model)\n",
    "    \n",
    "\n",
    "    # Evaluate the best model on the test data\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    #Apply classification report\n",
    "    print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem transformation: Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf': BinaryRelevance(classifier=GaussianNB(), require_dense=[True, True]), 'clf__classifier__var_smoothing': 1e-09}\n",
      "Best model:  Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.8, min_df=0.2, ngram_range=(1, 2),\n",
      "                                 stop_words=['au', 'aux', 'avec', 'ce', 'ces',\n",
      "                                             'dans', 'de', 'des', 'du', 'elle',\n",
      "                                             'en', 'et', 'eux', 'il', 'ils',\n",
      "                                             'je', 'la', 'le', 'les', 'leur',\n",
      "                                             'lui', 'ma', 'mais', 'me', 'même',\n",
      "                                             'mes', 'moi', 'mon', 'ne', 'nos', ...])),\n",
      "                ('tfidf', TfidfTransformer(norm='l1', sublinear_tf=True)),\n",
      "                ('clf',\n",
      "                 BinaryRelevance(classifier=GaussianNB(),\n",
      "                                 require_dense=[True, True]))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.608     1.000     0.756       730\n",
      "           1      0.000     0.000     0.000       413\n",
      "           2      0.000     0.000     0.000       208\n",
      "           3      0.000     0.000     0.000       226\n",
      "\n",
      "   micro avg      0.608     0.463     0.526      1577\n",
      "   macro avg      0.152     0.250     0.189      1577\n",
      "weighted avg      0.282     0.463     0.350      1577\n",
      " samples avg      0.608     0.481     0.522      1577\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = BinaryRelevance(GaussianNB())\n",
    "\n",
    "param_grid_binary_relevance = [\n",
    "    {\n",
    "        'clf': [clf],\n",
    "        'clf__classifier__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "    },\n",
    "    {\n",
    "        'clf': [BinaryRelevance(RandomForestClassifier())],\n",
    "        'clf__classifier__n_estimators': [50, 100],\n",
    "        'clf__classifier__max_depth': [10, 20],\n",
    "    },\n",
    "    #{\n",
    "    #    'clf': [BinaryRelevance(LogisticRegression())],\n",
    "    #    'clf__classifier__penalty': ['l1', 'l2'],\n",
    "    #    'clf__classifier__C': [0.1, 1, 10],\n",
    "    #    'clf__classifier__solver': ['liblinear', 'saga']\n",
    "    #}\n",
    "]\n",
    "\n",
    "make_pipeline(param_grid_binary_relevance, clf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
